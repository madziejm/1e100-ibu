{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madziejm/1e100-ibu/blob/master/1e100ibu_embedding_stars.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZMhH5l9MeZho"
      },
      "source": [
        "## Preliminary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CT48xPyXJHy9"
      },
      "source": [
        "#### Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sl9RJDTxJOTY",
        "outputId": "3bb55693-7c1c-4b16-b65f-eec4f76b2bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dev = cpu\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "dev = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "print(f'dev = {dev}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yet9JpBt8kcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a395d506-ff01-4a64-a079-9ed208a3936a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 78 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.6 MB 38.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 85.5 MB 1.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 68 kB 6.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.5 MB 65.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.8 MB 50.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 56.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 61.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 63.9 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 13.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 451 kB 62.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 10.1 MB 62.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 42 kB 1.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 628 kB 55.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 181 kB 79.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 87.9 MB 1.1 MB/s \n",
            "\u001b[?25h\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pl_core_news_md')\n",
            "Collecting en-core-web-sm==3.2.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.2.0/en_core_web_sm-3.2.0-py3-none-any.whl (13.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.9 MB 14.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<3.3.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from en-core-web-sm==3.2.0) (3.2.1)\n",
            "Requirement already satisfied: pathy>=0.3.5 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.6.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (21.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.6)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.1)\n",
            "Requirement already satisfied: typer<0.5.0,>=0.3.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.8 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.8)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.11.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (57.4.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.9.0,>=1.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.8.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.23.0)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.0.6)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.4.2)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (0.9.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.6)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.19.5)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (4.62.3)\n",
            "Requirement already satisfied: typing-extensions<4.0.0.0,>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.10.0.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.3.0)\n",
            "Requirement already satisfied: thinc<8.1.0,>=8.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (8.0.13)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from catalogue<2.1.0,>=2.0.6->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.7.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.7)\n",
            "Requirement already satisfied: smart-open<6.0.0,>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from pathy>=0.3.5->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (5.2.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2021.10.8)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from typer<0.5.0,>=0.3.0->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (7.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->spacy<3.3.0,>=3.2.0->en-core-web-sm==3.2.0) (2.0.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-3.2.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ],
      "source": [
        "!pip install icecream torchtext sentence_transformers faiss-cpu faiss-gpu fasttext --quiet\n",
        "!pip install spacy --upgrade --quiet\n",
        "!python3 -m spacy download pl_core_news_md --quiet\n",
        "!python3 -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from icecream import ic"
      ],
      "metadata": {
        "id": "ocdDAUoESbyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1MCM0dWB93e"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from torchtext._torchtext import (Vocab as VocabPybind) # make use of some hidden interface\n",
        "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import gc # garbage collector interface\n",
        "import io\n",
        "import re\n",
        "import spacy # nlp toolkit\n",
        "import torch\n",
        "import pickle\n",
        "\n",
        "\n",
        "class BaseReviews(torch.utils.data.Dataset):\n",
        "    def __init__(self, aspects, aspect_max, aspect_ratings, texts, unkn_tok, _len, anchor_words):\n",
        "        self.aspects = aspects\n",
        "        self.aspect_count = len(aspects)\n",
        "        self.aspect_max = aspect_max\n",
        "        self._aspect_ratings = aspect_ratings\n",
        "        self._texts = texts\n",
        "        self.unkn_tok = unkn_tok\n",
        "        self._len = _len\n",
        "        self.anchor_words = anchor_words\n",
        "        self.vocab = None\n",
        "\n",
        "    def dump(self, dest_path, filename):\n",
        "        contents = {\n",
        "            'aspects'        : self.aspects,\n",
        "            'aspect_max'     : self.aspect_max,\n",
        "            '_aspect_ratings': self._aspect_ratings,\n",
        "            '_texts'         : self._texts,\n",
        "            'unkn_tok'       : self.unkn_tok,\n",
        "            '_len'           : self._len,\n",
        "            'anchor_words'   : self.anchor_words,\n",
        "            'vocab'          : self.vocab,\n",
        "        }\n",
        "        with open(f'{dest_path}/{filename}', 'wb') as f:\n",
        "            pickle.dump(contents, f)\n",
        "    \n",
        "    def load(self, dest_path, filename):\n",
        "        with open(f'{dest_path}/{filename}', 'rb') as f:\n",
        "            contents = pickle.load(f)\n",
        "            self.aspects        = contents['aspects']\n",
        "            self.aspect_max     = contents['aspect_max']\n",
        "            self._aspect_ratings = contents['_aspect_ratings']\n",
        "            self._texts          = contents['_texts']\n",
        "            self.unkn_tok       = contents['unkn_tok']\n",
        "            self._len           = contents['_len']\n",
        "            self.anchor_words   = contents['anchor_words']\n",
        "            self.vocab          = contents['vocab']\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # # 1 # python\n",
        "        # sentences = tuple(sent for sent in self._texts[i])\n",
        "        # ratings = tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count))\n",
        "        # 2 # tensor\n",
        "        sentences = tuple(torch.LongTensor(sent) for sent in self._texts[i])\n",
        "        ratings = torch.LongTensor(tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count)))\n",
        "        # # 3 # dev\n",
        "        # sentences = tuple(torch.tensor(sent) for sent in self._texts[i])\n",
        "        # ratings = torch.tensor(tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count)))\n",
        "        return (sentences, ratings)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self._len"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P0TdTgU86K5q"
      },
      "outputs": [],
      "source": [
        "\n",
        "# filepath = './scrap-ocen-piwo/ocen-piwo-utf8.json'\n",
        "# aspect_count = 4 \n",
        "# aspect_ratings = [[] for _ in range(aspect_count)]\n",
        "# texts = []\n",
        "# _len = 0\n",
        "# with io.open(filepath, encoding='utf-8') as f:\n",
        "#     json_dict = json.loads(f.read())\n",
        "\n",
        "#     for i, reviews in enumerate(json_dict.values()):\n",
        "#         for sentences, ratings in reviews:\n",
        "#             _len += 1\n",
        "\n",
        "#             for aspect in range(aspect_count):\n",
        "#                 aspect_ratings[aspect].append(int(ratings[aspect]))\n",
        "\n",
        "#             texts.append(sentences)\n",
        "# # post_process(min_word_freq, max_word_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_seSugL6K5r"
      },
      "outputs": [],
      "source": [
        "# KEEEEEEEEEEEEEEEEEEEEEP THIS DON'T TOUCH THIS DON'T TOUCH THIS DON'T TOUCH THIS I WARNED YOU\n",
        "# wiki.pl.zip https://fasttext.cc/docs/en/pretrained-vectors.html\n",
        "# cc.pl.300.bin.gz https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.pl.300.bin.gz\n",
        "# word2vec.zip https://github.com/sdadas/polish-nlp-resources\n",
        "# fasttext_v2.zip https://github.com/sdadas/polish-nlp-resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0RQYdsL6K5s",
        "outputId": "a95a0896-dc5a-4081-e3d0-5ce1af518746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "try: # mount user's Google Drive if on Colab to save training artifacts\n",
        "    from google.colab import drive\n",
        "    drive.mount('/drive')\n",
        "    ROOT_DIR = '/content/'\n",
        "    MODEL_ROOT_DIR = '/drive/MyDrive/1e100ibu/saves'\n",
        "except ImportError:\n",
        "    ROOT_DIR = './'\n",
        "    MODEL_ROOT_DIR = './saves/'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2rKyNj16K5t"
      },
      "source": [
        "## ocen-piwo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5j7dcOw6K5t"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from torchtext._torchtext import (Vocab as VocabPybind) # make use of some hidden interface\n",
        "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import gc # garbage collector interface\n",
        "import io\n",
        "import re\n",
        "import spacy # nlp toolkit\n",
        "import torch\n",
        "import json\n",
        "from tqdm.contrib.concurrent import thread_map\n",
        "from typing import List\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "class OcenPiwoSBERTReviews(BaseReviews):\n",
        "    def __init__(self, vec_agg='avg'):\n",
        "        aspects = ['ogólny', 'smak', 'zapach', 'wygląd',]\n",
        "        super().__init__(\n",
        "            aspects        = aspects,\n",
        "            aspect_max     = [10, 10, 10, 10],\n",
        "            aspect_ratings = [ [] for _ in aspects ],\n",
        "            texts          = [],\n",
        "            unkn_tok       = '<unk>', # unknown/out of vocabulary token\n",
        "            _len            = 0,\n",
        "            anchor_words = {\n",
        "                'ogólny'     : ('ogólnie'),\n",
        "                'smak'       : ('smak'),\n",
        "                'zapach'     : ('zapach'),\n",
        "                'wygląd'     : ('wygląd', 'wygląda')\n",
        "            },\n",
        "        )\n",
        "        self.pipe = None\n",
        "        self.model = None\n",
        "        self._vec_agg = vec_agg\n",
        "\n",
        "    def dump(self, dest_path, filename): # override to use torch instead of pickle\n",
        "        contents = {\n",
        "            'aspects'        : self.aspects,\n",
        "            'aspect_max'     : self.aspect_max,\n",
        "            '_aspect_ratings': self._aspect_ratings,\n",
        "            '_texts'         : self._texts,\n",
        "            'unkn_tok'       : self.unkn_tok,\n",
        "            '_len'           : self._len,\n",
        "            'anchor_words'   : self.anchor_words,\n",
        "            'vocab'          : self.vocab,\n",
        "            'vec_agg'        : self._vec_agg\n",
        "        }\n",
        "        with open(f'{dest_path}/{filename}', 'wb') as f:\n",
        "            torch.save(contents, f)\n",
        "    \n",
        "    def load(self, dest_path, filename): # override to use torch instead of pickle; additionaly save whether to apply avg or maxpool\n",
        "        with open(f'{dest_path}/{filename}', 'rb') as f:\n",
        "            contents = torch.load(f, map_location=torch.device(dev))\n",
        "            self.aspects         = contents['aspects']\n",
        "            self.aspect_max      = contents['aspect_max']\n",
        "            self._aspect_ratings = contents['_aspect_ratings']\n",
        "            self._texts          = contents['_texts']\n",
        "            self.unkn_tok        = contents['unkn_tok']\n",
        "            self._len            = contents['_len']\n",
        "            self.anchor_words    = contents['anchor_words']\n",
        "            self.vocab           = contents['vocab']\n",
        "            self._vec_agg        = contents['vec_agg']\n",
        "\n",
        "    def build(self, filepath=f'{ROOT_DIR}/ocen-piwo-utf8.json'):\n",
        "        with io.open(filepath, encoding='utf-8') as f:\n",
        "            json_dict = json.loads(f.read())\n",
        "\n",
        "            for i, reviews in enumerate(json_dict.values()):\n",
        "                for sentences, ratings in reviews:\n",
        "                    self._len += 1\n",
        "                    if self._len > 10: # TODO remove\n",
        "                        break\n",
        "\n",
        "                    for aspect in range(self.aspect_count):\n",
        "                        self._aspect_ratings[aspect].append(int(ratings[aspect]))\n",
        "\n",
        "                    self._texts.append(sentences)\n",
        "        self._post_process()\n",
        "\n",
        "    def _fetch_nlp_pipeline(self):\n",
        "        if not self.pipe:\n",
        "            nlp = spacy.load('pl_core_news_md')\n",
        "            # we want sentencizer only, as tokenization is part of Transformer model we'll use\n",
        "            for pipe_name in nlp.pipe_names:\n",
        "                # if pipe_name != 'sentencizer':\n",
        "                nlp.remove_pipe(pipe_name)\n",
        "            nlp.add_pipe(\"sentencizer\", config={\"punct_chars\": ['.', '?', '!']})\n",
        "            self.pipe = nlp.pipe\n",
        "    \n",
        "    def _free_nlp_pipeline(self):\n",
        "        self.pipe = None\n",
        "    \n",
        "    def _fetch_transformer_model(self):\n",
        "        # self.model = model # TODO\n",
        "        if not self.model:\n",
        "            self.model = SentenceTransformer('distiluse-base-multilingual-cased-v1')\n",
        "    \n",
        "    def _free_transformer_model(self):\n",
        "        self.model = None\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # # 1 # python\n",
        "        # sentences = tuple(sent for sent in self._texts[i])\n",
        "        # ratings = tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count))\n",
        "        # 2 # tensor\n",
        "        sentences = self._texts[i]\n",
        "        ratings = torch.LongTensor(tuple(int(self._aspect_ratings[a][i]) for a in range(self.aspect_count)))\n",
        "        # # 3 # dev\n",
        "        # sentences = tuple(torch.tensor(sent) for sent in self._texts[i])\n",
        "        # ratings = torch.tensor(tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count)))\n",
        "        return (sentences, ratings)\n",
        "\n",
        "\n",
        "    def text_embedding(self, text: str):\n",
        "        self._fetch_transformer_model()\n",
        "        self._fetch_nlp_pipeline()\n",
        "        if 'avg' == self._vec_agg:\n",
        "            return self.model.encode([sent.text for sent in next(self.pipe([text])).sents], convert_to_tensor=True).mean(dim=0)\n",
        "        elif 'maxpool' == self._vec_agg:\n",
        "            return self.model.encode([sent.text for sent in next(self.pipe([text])).sents], convert_to_tensor=True).max(dim=0)[0]\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "    def sentences_avg_embedding(self, sentences: List[str]):\n",
        "        return self.model.encode(sentences, convert_to_tensor=True).mean(dim=0)\n",
        "\n",
        "    def sentences_maxpool_embedding(self, sentences: List[str]):\n",
        "        return self.model.encode(sentences, convert_to_tensor=True).max(dim=0)[0]\n",
        "    \n",
        "    def closest_indices(self, text: str, top_k=20):\n",
        "        text_emb = self.text_embedding(text)[None, :]\n",
        "        result = util.semantic_search(query_embeddings=text_emb, corpus_embeddings=self._texts, top_k=top_k)\n",
        "        return [(d['corpus_id'], d['score']) for d in result[0]]\n",
        "    \n",
        "    def knn_predict_rating(self, text: str, top_k=20):\n",
        "        knn = self.closest_indices(text, top_k)\n",
        "        indices, weights = [list(t) for t in zip(*knn)]\n",
        "        weights = torch.tensor(weights)\n",
        "        weights = weights / weights.sum()\n",
        "        nearest_ratings = torch.stack(tuple(self[idx][1] for idx in indices)).to(torch.float)\n",
        "        nearest_ratings *= weights[:, None]\n",
        "        nearest_ratings = nearest_ratings.sum(dim=0)\n",
        "        nearest_ratings.round_()\n",
        "        return nearest_ratings\n",
        "    \n",
        "    def _post_process(self):\n",
        "        print(\"Spacy pipe (sentence split)..\")\n",
        "        gc.collect() # force garbage collection\n",
        "        self._fetch_nlp_pipeline()\n",
        "        self._texts = [[sent.text for sent in doc.sents] for doc in self.pipe(self._texts)]\n",
        "        for i, text in enumerate(self._texts):\n",
        "            assert 0 != len(text) # make sure no empty reviews again (new could be introduced by removing stop words unfortunately)\n",
        "        print(\"Mapping reviews to embeddings..\")\n",
        "        gc.collect() # force garbage collection\n",
        "        self._fetch_transformer_model()\n",
        "        if 'avg' == self._vec_agg:\n",
        "            self._texts = torch.stack(thread_map(self.sentences_avg_embedding, self._texts, max_workers=1))\n",
        "        elif 'maxpool' == self._vec_agg:\n",
        "            self._texts = torch.stack(thread_map(self.sentences_maxpool_embedding, self._texts))\n",
        "        else:\n",
        "            assert False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uhsj8XiT6K5v",
        "outputId": "40b4aee5-3ffc-4884-ec24-0c4f79068953",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(34218, 0.7136959433555603), (39326, 0.686835527420044), (0, 0.6711326837539673), (3137, 0.65353924036026), (44595, 0.6387416124343872), (48338, 0.630121648311615), (47587, 0.5942672491073608), (50915, 0.5930118560791016), (50287, 0.5895595550537109), (15460, 0.5888326168060303), (29684, 0.5726549625396729), (50095, 0.571191132068634), (40925, 0.5640509128570557), (37764, 0.5573294162750244), (23545, 0.5545322895050049), (48275, 0.5462486147880554), (45120, 0.5414141416549683), (51075, 0.5395609140396118), (50259, 0.5389387607574463), (27861, 0.5347295999526978)]\n",
            "tensor([7., 6., 6., 7.])\n"
          ]
        }
      ],
      "source": [
        "op = OcenPiwoSBERTReviews(vec_agg='avg')\n",
        "# op.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# op.model = model # same as above\n",
        "op.load(dest_path=MODEL_ROOT_DIR, filename='ocen-piwo-avg-sbert-vecs.pt')\n",
        "# op.build(filepath='scrap-ocen-piwo/ocen-piwo-utf8.json')\n",
        "# op.dump(dest_path=MODEL_ROOT_DIR, filename='ocen-piwo-avg-sbert-vecs.pt')\n",
        "print(op.closest_indices('Jak dla mnie podstawka lepsza.')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(op.knn_predict_rating('Najgorsze piwo jakie piłem kiedykolwiek'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Mtjd09-6K5v",
        "outputId": "dc080e06-33df-4d09-9659-784863967ef8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(26590, -0.0023189131170511246), (26981, -0.002318914048373699), (30670, -0.002318916842341423), (38535, -0.0023189252242445946), (26830, -0.002318927086889744), (27893, -0.002318927086889744), (27548, -0.002318928949534893), (12812, -0.0023189298808574677), (21838, -0.0023189298808574677), (19831, -0.0023189308121800423), (156, -0.0023189326748251915), (19849, -0.002318933606147766), (32968, -0.002318933606147766), (27527, -0.0023189345374703407), (31864, -0.0023189345374703407), (13263, -0.0023189345374703407), (3333, -0.0023189345374703407), (33909, -0.0023189354687929153), (5588, -0.0023189354687929153), (13984, -0.0023189354687929153)]\n",
            "tensor([7., 7., 7., 7.])\n"
          ]
        }
      ],
      "source": [
        "op = OcenPiwoSBERTReviews(vec_agg='maxpool')\n",
        "# op.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# op.model = model # same as above\n",
        "# op.build('scrap-ocen-piwo/ocen-piwo-utf8.json')\n",
        "# op.dump(dest_path=MODEL_ROOT_DIR, filename='ocen-piwo-maxpool-sbert-vecs.pt')\n",
        "op.load(dest_path=MODEL_ROOT_DIR, filename='ocen-piwo-maxpool-sbert-vecs.pt')\n",
        "print(op.closest_indices('Jak dla mnie podstawka lepsza.')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(op.knn_predict_rating('Najgorsze piwo jakie piłem kiedykolwiek'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r07WXZDL6K5w",
        "outputId": "bbdde5a2-dff1-4329-d06a-29cda8406656"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.0024,  0.0811,  0.0436,  ...,  0.0494,  0.0345,  0.0467],\n",
              "        [-0.0249, -0.0587,  0.0530,  ..., -0.0004, -0.0866, -0.0431],\n",
              "        [ 0.0546,  0.0562,  0.0631,  ...,  0.0394,  0.0466,  0.0272],\n",
              "        ...,\n",
              "        [ 0.0469,  0.0107,  0.0090,  ..., -0.0862,  0.0251, -0.0680],\n",
              "        [ 0.0098,  0.0033,  0.0542,  ...,  0.0398,  0.0024,  0.0699],\n",
              "        [ 0.0589,  0.0671,  0.0504,  ...,  0.0879,  0.0689,  0.0741]])"
            ]
          },
          "execution_count": 251,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "op._texts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zWrvI0ov6K5w"
      },
      "outputs": [],
      "source": [
        "_aspect_ratings = [[], [], [], []]\n",
        "_texts = []\n",
        "\n",
        "with io.open(f'scrap-ocen-piwo/ocen-piwo-utf8.json', encoding='utf-8') as f:\n",
        "    json_dict = json.loads(f.read())\n",
        "\n",
        "    for i, reviews in enumerate(json_dict.values()):\n",
        "        for sentences, ratings in reviews:\n",
        "            # self._len += 1\n",
        "            # if self._len > 10: # TODO remove\n",
        "            #     break\n",
        "\n",
        "            for aspect in range(4):\n",
        "                _aspect_ratings[aspect].append(int(ratings[aspect]))\n",
        "\n",
        "            _texts.append(sentences)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u71KHJ2y6K5w",
        "outputId": "322a7809-883d-4b08-9d69-71eada63f63f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jak dla mnie poprawne .\n",
            "Jak dla mnie, dużo lepsze niż Royzbawiony. Jak najbardziej, polecam.\n",
            "Jak dla mnie podstawka lepsza. Wanilia i czekolada słabo wyczuwalne, ale nadal piwo jest niesamowicie gładkie i pełne. \n",
            "Po raz kolejny w przypadku Browaru Maryensztadt spotykam się z sytuacją, gdzie w opisie Hazy świeci jasno, że spodziewać się należy nut sosnowych i żywicznych, których tam zwyczajnie nie ma. Taki sam opis zastosowali w przypadku West Coastowej wersji serii \\\"The Roots\\\" - i tam również nut ani sosnowych, ani żywicznych nie było (chociaż tam akurat być powinny). Wracając do niniejszego: aromat piękny - głęboki, cytrusowy, bogaty. W smaku mamy zmętnioną IPkĘ, z bardzo wyraźną, zestową goryczką. Nie ma podanego ekstraktu, ale czuć że pozostała spora pełnia - daleko temu piwu do wytrawności. Z wyglądu przypomina sok z grejpfrutów, w fakturze jest gładkie, w odbiorze zagęszczone. Delfinki sobie pływają na etykiecie, a człowiek chłonie ów cudowny nektar z uśmiechem na ustach. Solidny wypust, w sumie to na poziomie Nevermindów. \n"
          ]
        }
      ],
      "source": [
        "print(_texts[34218])\n",
        "print(_texts[39326])\n",
        "print(_texts[0])\n",
        "print(_texts[31])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ToSWxp36K5x"
      },
      "source": [
        "### FastText"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qEbUSKUV6K5x"
      },
      "outputs": [],
      "source": [
        "from collections import Counter\n",
        "from torchtext._torchtext import (Vocab as VocabPybind) # make use of some hidden interface\n",
        "from torchtext.vocab import Vocab, build_vocab_from_iterator\n",
        "from tqdm.notebook import trange, tqdm\n",
        "import gc # garbage collector interface\n",
        "import io\n",
        "import re\n",
        "import spacy # nlp toolkit\n",
        "import torch\n",
        "import json\n",
        "from tqdm.contrib.concurrent import thread_map\n",
        "from typing import List\n",
        "import fasttext\n",
        "import fasttext.util\n",
        "import numpy as np\n",
        "import faiss\n",
        "from icecream import ic\n",
        "\n",
        "class OcenPiwoFasttextEmbeddedReviews(BaseReviews):\n",
        "    def __init__(self, vec_agg='avg'):\n",
        "        aspects = ['ogólny', 'smak', 'zapach', 'wygląd',]\n",
        "        super().__init__(\n",
        "            aspects        = aspects,\n",
        "            aspect_max     = [10, 10, 10, 10],\n",
        "            aspect_ratings = [ [] for _ in aspects ],\n",
        "            texts          = [],\n",
        "            unkn_tok       = '<unk>', # unknown/out of vocabulary token\n",
        "            _len            = 0,\n",
        "            anchor_words = {\n",
        "                'ogólny'     : ('ogólnie'),\n",
        "                'smak'       : ('smak'),\n",
        "                'zapach'     : ('zapach'),\n",
        "                'wygląd'     : ('wygląd', 'wygląda')\n",
        "            },\n",
        "        )\n",
        "        self.pipe = None\n",
        "        self.model = None\n",
        "        self._vec_agg = vec_agg\n",
        "        self._index = None\n",
        "\n",
        "    def dump(self, dest_path, filename): # override to use torch instead of pickle\n",
        "        contents = {\n",
        "            'aspects'        : self.aspects,\n",
        "            'aspect_max'     : self.aspect_max,\n",
        "            '_aspect_ratings': self._aspect_ratings,\n",
        "            '_texts'         : self._texts,\n",
        "            'unkn_tok'       : self.unkn_tok,\n",
        "            '_len'           : self._len,\n",
        "            'anchor_words'   : self.anchor_words,\n",
        "            'vocab'          : self.vocab,\n",
        "            'vec_agg'        : self._vec_agg\n",
        "        }\n",
        "        with open(f'{dest_path}/{filename}', 'wb') as f:\n",
        "            torch.save(contents, f)\n",
        "    \n",
        "    def load(self, dest_path, filename): # override to use torch instead of pickle; additionaly save whether to apply avg or maxpool\n",
        "        with open(f'{dest_path}/{filename}', 'rb') as f:\n",
        "            contents = torch.load(f, map_location=torch.device(dev))\n",
        "            self.aspects         = contents['aspects']\n",
        "            self.aspect_max      = contents['aspect_max']\n",
        "            self._aspect_ratings = contents['_aspect_ratings']\n",
        "            self._texts          = contents['_texts']\n",
        "            self.unkn_tok        = contents['unkn_tok']\n",
        "            self._len            = contents['_len']\n",
        "            self.anchor_words    = contents['anchor_words']\n",
        "            self.vocab           = contents['vocab']\n",
        "            self._vec_agg        = contents['vec_agg']\n",
        "\n",
        "    def build(self, filepath=f'{ROOT_DIR}/ocen-piwo-utf8.json'):\n",
        "        with io.open(filepath, encoding='utf-8') as f:\n",
        "            json_dict = json.loads(f.read())\n",
        "\n",
        "            for i, reviews in enumerate(json_dict.values()):\n",
        "                for sentences, ratings in reviews:\n",
        "                    self._len += 1\n",
        "                    if self._len > 1000: # TODO remove\n",
        "                        break\n",
        "\n",
        "                    for aspect in range(self.aspect_count):\n",
        "                        self._aspect_ratings[aspect].append(int(ratings[aspect]))\n",
        "\n",
        "                    self._texts.append(sentences)\n",
        "        self._post_process()\n",
        "\n",
        "    def _fetch_nlp_pipeline(self):\n",
        "        if not self.pipe:\n",
        "            nlp = spacy.load('pl_core_news_md')\n",
        "            # we want sentencizer only, as tokenization is part of Transformer model we'll use\n",
        "            # ic(nlp.pipe_names) # 'tok2vec', 'morphologizer', 'parser', 'tagger', 'attribute_ruler', 'lemmatizer', 'ner'\n",
        "            for pipe_name in nlp.pipe_names:\n",
        "                if pipe_name not in ['tokenizer', 'lemmatizer']:\n",
        "                    nlp.remove_pipe(pipe_name)\n",
        "            nlp.add_pipe(\"sentencizer\", config={\"punct_chars\": ['.', '?', '!']})\n",
        "            self.pipe = lambda texts: [[tok.lemma_ for sent in doc.sents for tok in sent if not tok.is_punct and not tok.is_space] for doc in nlp.pipe(texts)] # TODO remove stop words? (not tok.is_stop)\n",
        "    \n",
        "    def _free_nlp_pipeline(self):\n",
        "        self.pipe = None\n",
        "    \n",
        "    def _fetch_model(self):\n",
        "        if not self.model:\n",
        "            self.model = fasttext.load_model(f'{MODEL_ROOT_DIR}/../vectors/cc.pl.300.bin')\n",
        "    \n",
        "    def _free_model(self):\n",
        "        self.model = None\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        # # 1 # python\n",
        "        # sentences = tuple(sent for sent in self._texts[i])\n",
        "        # ratings = tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count))\n",
        "        # 2 # tensor\n",
        "        sentences = self._texts[i]\n",
        "        ratings = torch.LongTensor(tuple(int(self._aspect_ratings[a][i]) for a in range(self.aspect_count)))\n",
        "        # # 3 # dev\n",
        "        # sentences = tuple(torch.tensor(sent) for sent in self._texts[i])\n",
        "        # ratings = torch.tensor(tuple(self._aspect_ratings[a][i] for a in range(self.aspect_count)))\n",
        "        return (sentences, ratings)\n",
        "\n",
        "\n",
        "    def text_embedding(self, text: str):\n",
        "        \"\"\"tokenize text, and return mean/maxpool of the token vectors \"\"\"\n",
        "        self._fetch_nlp_pipeline()\n",
        "        self._fetch_model()\n",
        "        words = self.pipe([text])[0] # self.pipe is for list of texts and returns a list; we grab oth list of the result because of this\n",
        "        vecs = np.vstack([self.model[word] for word in words])\n",
        "        if 'avg' == self._vec_agg:\n",
        "            return vecs.mean(axis=0)\n",
        "        elif 'maxpool' == self._vec_agg:\n",
        "            return vecs.max(axis=0)\n",
        "        else:\n",
        "            assert False\n",
        "\n",
        "    def words_avg_embedding(self, words: List[str]):\n",
        "        \"\"\" treat words as bag of words, return average of their vectors \"\"\"\n",
        "        vecs = np.vstack([self.model[word] for word in words])\n",
        "        return vecs.mean(axis=0)\n",
        "\n",
        "    def words_maxpool_embedding(self, words: List[str]):\n",
        "        \"\"\" treat words as bag of words, return max of their vectors (position-wise) \"\"\"\n",
        "        vecs = np.vstack([self.model[word] for word in words])\n",
        "        return vecs.max(axis=0)\n",
        "    \n",
        "    def closest_indices(self, text: str, top_k=20):\n",
        "        self._set_up_texts_index()\n",
        "        text_emb = self.text_embedding(text)[None, :] # introduce new dimension for vector count (here only 1 vector)\n",
        "        result = self._index.search(text_emb, top_k)\n",
        "        # result[0] is list of similiarities list, result[1] is list of list\n",
        "        # we get [0] which means result for 0th vector passed to search (the single one we passed)\n",
        "        result = (result[0][0], result[1][0])\n",
        "        return result\n",
        "    \n",
        "    def knn_predict_rating(self, text: str, top_k=10):\n",
        "        knn = self.closest_indices(text, top_k)\n",
        "        weights, indices = knn\n",
        "        weights = np.array(weights)\n",
        "        weights = weights / weights.sum()\n",
        "        nearest_ratings = np.vstack(tuple(self[idx][1] for idx in indices)).astype(np.float32)\n",
        "        nearest_ratings *= weights[:, None]\n",
        "        nearest_ratings = nearest_ratings.sum(axis=0)\n",
        "        nearest_ratings = np.rint(nearest_ratings)\n",
        "        return nearest_ratings\n",
        "    \n",
        "    def _set_up_texts_index(self):\n",
        "        \"\"\"set up index for vector-encoded corpora texts\"\"\"\n",
        "        if self._index is None:\n",
        "            if hasattr(faiss, 'StandardGpuResources'):\n",
        "                # gpu mode\n",
        "                res = faiss.StandardGpuResources()\n",
        "                config = faiss.GpuIndexFlatConfig()\n",
        "                config.device = 0\n",
        "                self._index = faiss.GpuIndexFlatIP(res, self._texts.shape[1], config)\n",
        "            else:\n",
        "                # cpu mode\n",
        "                self._index = faiss.IndexFlatIP(self._texts.shape[1])\n",
        "            self._index.add(self._texts)\n",
        "    \n",
        "    def _post_process(self):\n",
        "        print(\"Spacy pipe (sentence split&tokenization)..\")\n",
        "        gc.collect() # force garbage collection\n",
        "        self._fetch_nlp_pipeline()\n",
        "        self._texts = self.pipe(self._texts)\n",
        "        i = 0\n",
        "        while True:\n",
        "            if len(self._texts) <= i:\n",
        "                break\n",
        "            if 0 == len(self._texts[i]): # review with no tokens -> remove\n",
        "                del self._texts[i]\n",
        "                for a_idx, _ in enumerate(self.aspects):\n",
        "                    del self._aspect_ratings[a_idx][i]\n",
        "            else:\n",
        "                i += 1\n",
        "        for i, text in enumerate(self._texts):\n",
        "            assert 0 != len(text) # make sure no empty reviews again (new could be introduced by removing stop words unfortunately)\n",
        "        print(\"Mapping reviews to embeddings..\")\n",
        "        # gc.collect() # force garbage collection\n",
        "        self._fetch_model()\n",
        "        if 'avg' == self._vec_agg:\n",
        "            self._texts = np.vstack(thread_map(self.words_avg_embedding, self._texts, max_workers=1))\n",
        "        elif 'maxpool' == self._vec_agg:\n",
        "            self._texts = np.vstack(thread_map(self.words_maxpool_embedding, self._texts))\n",
        "        else:\n",
        "            assert False\n",
        "        self._set_up_texts_index()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJuY8oCN6K5y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4774ff9-bb81-46ac-97ac-ed8bbb33b239"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([0.67781323, 0.67781323, 0.67781323, 0.6574119 , 0.6559805 ,\n",
            "       0.652663  , 0.644583  , 0.64412564, 0.6435037 , 0.63613886,\n",
            "       0.6300584 , 0.6300584 , 0.6300584 , 0.62572926, 0.62572926,\n",
            "       0.6112176 , 0.61084837, 0.60827816, 0.6010281 , 0.59375834],\n",
            "      dtype=float32), array([43432, 43433, 45054, 45768, 43055, 34215, 11536, 13352,  8679,\n",
            "       36913,  5345, 50258, 43930, 29681, 45117, 24531, 47999, 36136,\n",
            "         400, 36196]))\n",
            "[7. 7. 7. 7.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        }
      ],
      "source": [
        "op = OcenPiwoFasttextEmbeddedReviews(vec_agg='avg')\n",
        "# op.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# op.model = model # same as above\n",
        "# op.load(dest_path=ROOT_DIR, filename='ocen-piwo-avg-fasttext-vecs.pt')\n",
        "# op.build(filepath=f'{MODEL_ROOT_DIR}/../ocen-piwo-utf8.json')\n",
        "op.load(dest_path=MODEL_ROOT_DIR, filename='ocen-piwo-avg-fasttext-vecs.pt')\n",
        "print(op.closest_indices('Jak dla mnie podstawka lepsza.')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(op.knn_predict_rating('Najgorsze piwo jakie piłem kiedykolwiek'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzaNwZ816K5y"
      },
      "outputs": [],
      "source": [
        "pipe = op.pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "model = op.model # same as above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4CrUKkyN6K5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b625e1-5f5f-486c-a0bb-9e2dfcbe60b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([8.013512 , 7.6783237, 7.6622777, 7.6002817, 7.5900207, 7.580925 ,\n",
            "       7.5770082, 7.558087 , 7.524187 , 7.519915 , 7.4981885, 7.472593 ,\n",
            "       7.440344 , 7.4395576, 7.417118 , 7.41661  , 7.41541  , 7.405194 ,\n",
            "       7.391786 , 7.381966 ], dtype=float32), array([30667,  1191, 27869,    74, 49198,  5116,  8917, 39136,  2828,\n",
            "       38532, 28121, 12981,   374, 48226, 27548, 21943, 31675, 13200,\n",
            "       22314, 43310]))\n",
            "[6. 6. 6. 6.]\n"
          ]
        }
      ],
      "source": [
        "# pipe = op.pipe\n",
        "op = OcenPiwoFasttextEmbeddedReviews(vec_agg='maxpool')\n",
        "op.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "op.model = model # same as above\n",
        "# op.load(dest_path=ROOT_DIR, filename='ocen-piwo-maxpool-fasttext-vecs.pt')\n",
        "# op.build(filepath=f'{MODEL_ROOT_DIR}/../ocen-piwo-utf8.json')\n",
        "op.load(dest_path=MODEL_ROOT_DIR, filename='ocen-piwo-maxpool-fasttext-vecs.pt')\n",
        "print(op.closest_indices('Jak dla mnie podstawka lepsza.')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(op.knn_predict_rating('Najgorsze piwo jakie piłem kiedykolwiek'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7YBTodan6K5z",
        "outputId": "33b3dee3-fde7-4a75-ff57-27e4efa8a609"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1000, 300)"
            ]
          },
          "execution_count": 195,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "op._texts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VmyFRjMK6K5z",
        "outputId": "201f5dd2-8176-40c6-b58e-371fef53a6d3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['zdanie', 'zdanie', 'więcej', 'zdań']]"
            ]
          },
          "execution_count": 190,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "op.pipe(['zdanie. zdanie więcej zdań'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eADJsSt36K50",
        "outputId": "4513ff7e-dfe1-452c-bc98-81976b83eff8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([0.810998  , 0.5597369 , 0.5336927 , 0.47305262, 0.4185194 ,\n",
              "        0.41583222, 0.3911564 , 0.38290936, 0.3657134 , 0.36255878,\n",
              "        0.362181  , 0.3595591 , 0.3593543 , 0.35257733, 0.35224316,\n",
              "        0.34823546, 0.34764293, 0.34656692, 0.3448577 , 0.3425097 ],\n",
              "       dtype=float32),\n",
              " array([ 58,   7, 811, 377, 528, 697, 400, 499,  19, 642, 359, 805, 773,\n",
              "        352, 989, 898, 851, 849, 126, 208]))"
            ]
          },
          "execution_count": 191,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "op.closest_indices('Fatalne piwo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPmOhSMH6K50",
        "outputId": "330bfbe0-52f3-46de-9186-18e634827617"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7., 7., 7., 7.], dtype=float32)"
            ]
          },
          "execution_count": 192,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "op.knn_predict_rating('Fatalne piwo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aE4Fq1jP6K50",
        "outputId": "a8324df1-e4a5-42fc-e906-512c9ca55a90"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "sztos piwo \n",
            "\n",
            "Pierwszy raz wylałem piwo...  \n",
            "\n",
            "Piwo dobre. Bardzo mocno gazowane. \n",
            "\n",
            "Alko jak na piwo niemal świeże, genialnie ukryte \n",
            "\n",
            "Moim zdaniem bardzo dobre piwo! Słodkie, tak jak rogal. Wyczuwalny smak jego smak.  \n",
            "\n",
            "Piwo jak na 7,2% mało alkoholowe. To dobrze bo nie wali spirytusem. Całkiem smaczne jak na piwo w tej cenie \n",
            "\n",
            "Już :-) \n",
            "\n",
            "Smakuje bardziej jak piwo z Gościszewa niż jak pils. Nie jest złe, ale ze ze stylem mało wspólnego. \n",
            "\n",
            "Pij, lepsze już nie będzie, bo tu nie ma się co ułożyć, może jakieś nuty miodowe dojdą, ale też i większy sos sojowy \n",
            "\n",
            "Piwo bardzo smaczne, świetnie gra Sabro z mętnością. Piwo świetne, raper do kolaboracji słaby. \n",
            "\n",
            "Piwo wodniste. Piłem zimne więc miałem trochę zaburzone zmysły ale smak bardzo zbliżony do wody. Z puszki nie śmierdziało więc nie jest źle  \n",
            "\n",
            "Zdecydowanie, lekkie, sesyjne, gładkie i przyjemne. Idealne jeśli ktoś ma ochotę na takie piwo. \n",
            "\n",
            "Całkiem dobre. Czuć chmiel. Troszkę też alkoholowe. Lekko metaliczne. Da się pić  \n",
            "\n",
            "Piwo delikatnie metaliczne. Goryczka niska choć wyczuwalna. Mało słodkie. Dosyć wytrawne  \n",
            "\n",
            "Kiepskie piwo i tyle. Z belgijskim triplem nie ma nic wspólnego. \n",
            "\n",
            "To jest to samo piwo co budvar strong. To jest nowa etykieta i nazwa. \n",
            "\n",
            "Gazowany, słodko-kwaśny sok owocowy - nie zbliżać się !!! \n",
            "\n",
            "Piwo ciemne i goryczkowe. Dosyć słodkie ale ma tą kawową goryczkę. Z tyłu posmak Coli. Całkiem dobre jak za tą cenę  \n",
            "\n",
            "Dobre, mocno przyprawione świąteczne piwo. Lepsze niż wersja jasnego ale. Widawa to zawsze wysoki poziom. \n",
            "\n",
            "O takie piwo nic nie robiłem:)Tak na serio to me gusta!Trafia mocno w mój gust. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in [ 58,   7, 811, 377, 528, 697, 400, 499,  19, 642, 359, 805, 773,\n",
        "        352, 989, 898, 851, 849, 126, 208]:\n",
        "# for i in [400, 605, 540, 269, 323, 560, 499,  19, 857, 624, 528, 234,   0,\n",
        "#                     697, 581, 898, 781, 601, 322,  21]:\n",
        "    print(_texts[i], '\\n')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLsETpEO6K51"
      },
      "source": [
        "## SNAP RateBeer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhxZug_W6K51"
      },
      "source": [
        "### SBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz7Ipeso6K51"
      },
      "outputs": [],
      "source": [
        "class RateBeerSBERTReviews(OcenPiwoSBERTReviews):\n",
        "    \"\"\"\n",
        "    beer/name: John Harvards Simcoe IPA\n",
        "    beer/beerId: 63836\n",
        "    beer/brewerId: 8481\n",
        "    beer/ABV: 5.4\n",
        "    beer/style: India Pale Ale &#40;IPA&#41;\n",
        "    review/appearance: 4/5\n",
        "    review/aroma: 6/10\n",
        "    review/palate: 3/5\n",
        "    review/taste: 6/10\n",
        "    review/overall: 13/20\n",
        "    review/time: 1157587200\n",
        "    review/profileName: hopdog\n",
        "    review/text: On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.\n",
        "    \"\"\"\n",
        "    def __init__(self, vec_agg='avg'):\n",
        "        aspects = ['appearance', 'aroma', 'palate', 'taste', 'overall']\n",
        "        BaseReviews.__init__(\n",
        "            self,\n",
        "            aspects        = aspects,\n",
        "            aspect_max     = [5, 10, 5, 10, 20],\n",
        "            aspect_ratings = [ [] for _ in aspects ],\n",
        "            texts          = [],\n",
        "            unkn_tok       = '<unk>', # unknown/out of vocabulary token\n",
        "            _len            = 0,\n",
        "            anchor_words = {\n",
        "                'appearance' : ('appearance', 'color'),\n",
        "                'aroma'      : ('aroma'),\n",
        "                'palate'     : ('palate', 'mouthfeel'),\n",
        "                'taste'      : ('taste'),\n",
        "                'overall'    : ('overall'),\n",
        "            },\n",
        "        )\n",
        "        self.pipe = None\n",
        "        self.model = None\n",
        "        self._vec_agg = vec_agg\n",
        "\n",
        "    def build(self, filepath=f'{ROOT_DIR}/SNAP-Ratebeer.txt', max_reviews=float('inf')):\n",
        "        with io.open(filepath, encoding='utf-8') as f:\n",
        "            for line in tqdm(f, total=(40938282 if max_reviews == float('inf') else max_reviews * 14), desc='Reading data'):\n",
        "                if line == '\\n': # separator\n",
        "                    self._len += 1\n",
        "                    if max_reviews <= self._len:\n",
        "                        break\n",
        "                elif line.startswith('review/appearance: '):\n",
        "                    line = line[len('review/appearance: '):]\n",
        "                    self._aspect_ratings[0].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/aroma: '):\n",
        "                    line = line[len('review/aroma: '):]\n",
        "                    self._aspect_ratings[1].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/palate: '):\n",
        "                    line = line[len('review/palate: '):]\n",
        "                    self._aspect_ratings[2].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/taste: '):\n",
        "                    line = line[len('review/taste: '):]\n",
        "                    self._aspect_ratings[3].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/overall: '):\n",
        "                    line = line[len('review/overall: '):]\n",
        "                    self._aspect_ratings[4].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/text: '):\n",
        "                    line = line[len('review/text: '):]\n",
        "                    if line.startswith('UPDATED:'):\n",
        "                        line = line[len(\"UPDATED: APR 29, 2008\"):] # drop prefix\n",
        "                    line = re.sub('~', ' ', line.strip()) # remove whitespace incl. trailing newline and tildes that can be found in data for some reason\n",
        "                    if line:\n",
        "                        self._texts.append(line)\n",
        "                    else: # some reviews do not have associated text; unwind (remove) their ratings for each aspect\n",
        "                        for aspect_ratings in self._aspect_ratings:\n",
        "                            aspect_ratings.pop()\n",
        "                        self._len -= 1\n",
        "        gc.collect()\n",
        "        self._post_process()\n",
        "    \n",
        "    def _fetch_nlp_pipeline(self):\n",
        "        if not self.pipe:\n",
        "            nlp = spacy.util.get_lang_class('en')()\n",
        "            # we want sentencizer only, as tokenization is part of Transformer model we'll use\n",
        "            for pipe_name in nlp.pipe_names:\n",
        "                # if pipe_name != 'sentencizer':\n",
        "                nlp.remove_pipe(pipe_name)\n",
        "            nlp.add_pipe(\"sentencizer\", config={\"punct_chars\": ['.', '?', '!']})\n",
        "            self.pipe = nlp.pipe\n",
        "    \n",
        "    def _free_nlp_pipeline(self):\n",
        "        self.nlp = None\n",
        "\n",
        "    # def tokenize_reviews(self, reviews_texts: str):\n",
        "    #     return [tuple(list(tok.lower_ for tok in sent if not tok.is_stop and not tok.is_punct and not tok.is_space and len(tok) > 2) for sent in doc.sents if 0 != len(sent)) for doc in self.pipe(reviews_texts)]\n",
        "    \n",
        "    # def id_map_reviews(self, texts):\n",
        "    #     return [tuple(self.vocab.lookup_indices(sent) for sent in text) for text in texts]\n",
        "    \n",
        "    # def _post_process(self, min_word_freq=None, max_word_count=None):\n",
        "    #     assert (min_word_freq is not None) ^ bool(max_word_count is not None), \"provide one of min_word_freq and max_word_count\"\n",
        "    #     self._fetch_nlp_pipeline()\n",
        "    #     print(\"Spacy pipe (tokenization&sentence split)..\")\n",
        "    #     gc.collect() # force garbage collection\n",
        "    #     self._texts = self.tokenize_reviews(self._texts)\n",
        "    #     for i, text in enumerate(self._texts):\n",
        "    #         assert 0 != len(text) # make sure no empty reviews again (new could be introduced by removing stop words unfortunately)\n",
        "    #     print(\"Building vocab (word-id mapping)..\")\n",
        "    #     gc.collect() # force garbage collection\n",
        "    #     sent_gen = (sent for text in self._texts for sent in text)\n",
        "    #     if min_word_freq:\n",
        "    #         self.vocab = build_vocab_from_iterator(sent_gen, specials=[self.unkn_tok], min_word_freq=5)\n",
        "    #     else:\n",
        "    #         words = Counter()\n",
        "    #         for tokens in sent_gen:\n",
        "    #             words.update(tokens)\n",
        "    #         words = [word for word, freq in words.most_common(max_word_count)] # list sorted by frequency yikees\n",
        "    #         self.vocab = Vocab(VocabPybind(words, None))\n",
        "    #     self.vocab.insert_token(self.unkn_tok, 0)\n",
        "    #     self.vocab.set_default_index(self.vocab[self.unkn_tok]) # set index for out-of-vocabulary words\n",
        "    #     print(\"Mapping words to ids..\")\n",
        "    #     gc.collect() # force garbage collection\n",
        "    #     self._texts = self.id_map_reviews(self._texts)\n",
        "    #     gc.collect() # force garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del pipe\n",
        "del model\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ACS7narEAJo",
        "outputId": "9f2a5e90-a03f-4192-f0bb-1e2f4115f747"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "398"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IE07qKc6K52",
        "outputId": "85b4d4e4-23ba-4819-ea83-ce60687ba506"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(620508, 0.8770755529403687),\n",
              " (444881, 0.8675256967544556),\n",
              " (912710, 0.859946608543396),\n",
              " (799504, 0.8599153757095337),\n",
              " (867250, 0.8585574626922607),\n",
              " (799580, 0.8368151187896729),\n",
              " (798760, 0.834177553653717),\n",
              " (805445, 0.8265045881271362),\n",
              " (809532, 0.8252588510513306),\n",
              " (805801, 0.8247320652008057),\n",
              " (913585, 0.8208469152450562),\n",
              " (444829, 0.8176125288009644),\n",
              " (446641, 0.8164716362953186),\n",
              " (799523, 0.815644383430481),\n",
              " (798185, 0.8151065111160278),\n",
              " (319360, 0.8117756247520447),\n",
              " (915462, 0.8114019632339478),\n",
              " (101608, 0.8098669648170471),\n",
              " (273363, 0.8085517883300781),\n",
              " (806253, 0.8084362745285034)]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "rb = RateBeerSBERTReviews(vec_agg='avg')\n",
        "# rb.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# rb.model = model # same as above\n",
        "# rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-avg-sbert-vecs.pt')\n",
        "# rb.build(filepath='/drive/MyDrive/Colab Notebooks/1e100ibu/SNAP-Ratebeer.txt', max_reviews=1e6)\n",
        "rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-avg-sbert-vecs.pt')\n",
        "rb.closest_indices('Worst beer i have ever seen') # check: this input is 0-th review from the dataset, so hope for 0 be the most similar"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(rb.closest_indices('Worst beer i have ever seen')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(rb.knn_predict_rating('Tastes best from bottle. Not so heap as one could think. Nice hoppy smell. I had not supposed it will be sour though. Beautiful smooth head.'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFkZZQkcCZMa",
        "outputId": "045c733e-7ae4-465c-d7ba-c49148441466"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(620508, 0.8770755529403687), (444881, 0.8675256967544556), (912710, 0.859946608543396), (799504, 0.8599153757095337), (867250, 0.8585574626922607), (799580, 0.8368151187896729), (798760, 0.834177553653717), (805445, 0.8265045881271362), (809532, 0.8252588510513306), (805801, 0.8247320652008057), (913585, 0.8208469152450562), (444829, 0.8176125288009644), (446641, 0.8164716362953186), (799523, 0.815644383430481), (798185, 0.8151065111160278), (319360, 0.8117756247520447), (915462, 0.8114019632339478), (101608, 0.8098669648170471), (273363, 0.8085517883300781), (806253, 0.8084362745285034)]\n",
            "tensor([ 3.,  6.,  3.,  6., 12.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = rb.pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "model = rb.model # same as above"
      ],
      "metadata": {
        "id": "n6nZus42-h_P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "po4932eK6K52",
        "outputId": "7b2af541-cff4-4faa-a076-4aadaccecbce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(620508, 0.8770755529403687), (444881, 0.8675256967544556), (912710, 0.859946608543396), (799504, 0.8599153757095337), (799580, 0.8368151187896729), (798760, 0.834177553653717), (805445, 0.8265045881271362), (444829, 0.8176125288009644), (446641, 0.8164716362953186), (319360, 0.8117756247520447), (915462, 0.8114019632339478), (273363, 0.8085517883300781), (806253, 0.8084362745285034), (403988, 0.8071106672286987), (248957, 0.8060749173164368), (866862, 0.8004712462425232), (443889, 0.7977471351623535), (911407, 0.7967453002929688), (867250, 0.7954858541488647), (815882, 0.7952635288238525)]\n",
            "tensor([ 3.,  6.,  3.,  6., 12.])\n"
          ]
        }
      ],
      "source": [
        "rb = RateBeerSBERTReviews(vec_agg='maxpool')\n",
        "# rb.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# rb.model = model # same as above\n",
        "# rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-maxpool-sbert-vecs.pt')\n",
        "# rb.build(filepath='/drive/MyDrive/Colab Notebooks/1e100ibu/SNAP-Ratebeer.txt', max_reviews=1e6)\n",
        "rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-maxpool-sbert-vecs.pt')\n",
        "print(rb.closest_indices('Worst beer i have ever seen')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(rb.knn_predict_rating('Tastes best from bottle. Not so heap as one could think. Nice hoppy smell. I had not supposed it will be sour though. Beautiful smooth head.'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aoW3OM4r6K53"
      },
      "source": [
        "### Fasttext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIqmsRNY6K53"
      },
      "outputs": [],
      "source": [
        "class RateBeerFasttextReviews(OcenPiwoFasttextEmbeddedReviews):\n",
        "    \"\"\"\n",
        "    beer/name: John Harvards Simcoe IPA\n",
        "    beer/beerId: 63836\n",
        "    beer/brewerId: 8481\n",
        "    beer/ABV: 5.4\n",
        "    beer/style: India Pale Ale &#40;IPA&#41;\n",
        "    review/appearance: 4/5\n",
        "    review/aroma: 6/10\n",
        "    review/palate: 3/5\n",
        "    review/taste: 6/10\n",
        "    review/overall: 13/20\n",
        "    review/time: 1157587200\n",
        "    review/profileName: hopdog\n",
        "    review/text: On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.\n",
        "    \"\"\"\n",
        "    def __init__(self, vec_agg='avg'):\n",
        "        aspects = ['appearance', 'aroma', 'palate', 'taste', 'overall']\n",
        "        BaseReviews.__init__(\n",
        "            self,\n",
        "            aspects        = aspects,\n",
        "            aspect_max     = [5, 10, 5, 10, 20],\n",
        "            aspect_ratings = [ [] for _ in aspects ],\n",
        "            texts          = [],\n",
        "            unkn_tok       = '<unk>', # unknown/out of vocabulary token\n",
        "            _len            = 0,\n",
        "            anchor_words = {\n",
        "                'appearance' : ('appearance', 'color'),\n",
        "                'aroma'      : ('aroma'),\n",
        "                'palate'     : ('palate', 'mouthfeel'),\n",
        "                'taste'      : ('taste'),\n",
        "                'overall'    : ('overall'),\n",
        "            },\n",
        "        )\n",
        "        self.pipe = None\n",
        "        self.model = None\n",
        "        self._vec_agg = vec_agg\n",
        "        self._index = None\n",
        "\n",
        "    def build(self, filepath=f'{ROOT_DIR}/SNAP-Ratebeer.txt', max_reviews=float('inf')):\n",
        "        with io.open(filepath, encoding='utf-8') as f:\n",
        "            for line in tqdm(f, total=(40938282 if max_reviews == float('inf') else max_reviews * 14), desc='Reading data'):\n",
        "                if line == '\\n': # separator\n",
        "                    self._len += 1\n",
        "                    if max_reviews <= self._len:\n",
        "                        break\n",
        "                elif line.startswith('review/appearance: '):\n",
        "                    line = line[len('review/appearance: '):]\n",
        "                    self._aspect_ratings[0].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/aroma: '):\n",
        "                    line = line[len('review/aroma: '):]\n",
        "                    self._aspect_ratings[1].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/palate: '):\n",
        "                    line = line[len('review/palate: '):]\n",
        "                    self._aspect_ratings[2].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/taste: '):\n",
        "                    line = line[len('review/taste: '):]\n",
        "                    self._aspect_ratings[3].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/overall: '):\n",
        "                    line = line[len('review/overall: '):]\n",
        "                    self._aspect_ratings[4].append(int(line.split('/')[0])) # lhs of split by '/' is rating, rhs is max possible rating\n",
        "                elif line.startswith('review/text: '):\n",
        "                    line = line[len('review/text: '):]\n",
        "                    if line.startswith('UPDATED:'):\n",
        "                        line = line[len(\"UPDATED: APR 29, 2008\"):] # drop prefix\n",
        "                    line = re.sub('~', ' ', line.strip()) # remove whitespace incl. trailing newline and tildes that can be found in data for some reason\n",
        "                    if line:\n",
        "                        self._texts.append(line)\n",
        "                    else: # some reviews do not have associated text; unwind (remove) their ratings for each aspect\n",
        "                        for aspect_ratings in self._aspect_ratings:\n",
        "                            aspect_ratings.pop()\n",
        "                        self._len -= 1\n",
        "        gc.collect()\n",
        "        self._post_process()\n",
        "    \n",
        "    def _fetch_nlp_pipeline(self):\n",
        "        if not self.pipe:\n",
        "            nlp = spacy.load('en_core_web_sm')\n",
        "            # nlp = spacy.util.get_lang_class('en')() # this has strange api so won't use it here\n",
        "            # we want sentencizer only, as tokenization is part of Transformer model we'll use\n",
        "            # ic(nlp.pipe_names) # 'tok2vec', 'morphologizer', 'parser', 'tagger', 'attribute_ruler', 'lemmatizer', 'ner'\n",
        "            for pipe_name in nlp.pipe_names:\n",
        "                if pipe_name not in ['tokenizer']:\n",
        "                    nlp.remove_pipe(pipe_name)\n",
        "            nlp.add_pipe(\"sentencizer\", config={\"punct_chars\": ['.', '?', '!']})\n",
        "            self.pipe = lambda texts: [[tok.lower_ for sent in doc.sents for tok in sent if not tok.is_punct and not tok.is_space] for doc in nlp.pipe(texts)] # TODO remove stop words? (not tok.is_stop); do not lowercase?\n",
        "    \n",
        "    def _fetch_model(self):\n",
        "        if not self.model:\n",
        "            self.model = fasttext.load_model(f'{MODEL_ROOT_DIR}/../vectors/cc.en.300.bin')\n",
        "    \n",
        "    \n",
        "    # def _free_nlp_pipeline(self):\n",
        "    #     self.nlp = None\n",
        "\n",
        "    # def tokenize_reviews(self, reviews_texts: str):\n",
        "    #     return [tuple(list(tok.lower_ for tok in sent if not tok.is_stop and not tok.is_punct and not tok.is_space and len(tok) > 2) for sent in doc.sents if 0 != len(sent)) for doc in self.pipe(reviews_texts)]\n",
        "    \n",
        "    # def id_map_reviews(self, texts):\n",
        "    #     return [tuple(self.vocab.lookup_indices(sent) for sent in text) for text in texts]\n",
        "    \n",
        "    # def _post_process(self, min_word_freq=None, max_word_count=None):\n",
        "    #     assert (min_word_freq is not None) ^ bool(max_word_count is not None), \"provide one of min_word_freq and max_word_count\"\n",
        "    #     self._fetch_nlp_pipeline()\n",
        "    #     print(\"Spacy pipe (tokenization&sentence split)..\")\n",
        "    #     gc.collect() # force garbage collection\n",
        "    #     self._texts = self.tokenize_reviews(self._texts)\n",
        "    #     for i, text in enumerate(self._texts):\n",
        "    #         assert 0 != len(text) # make sure no empty reviews again (new could be introduced by removing stop words unfortunately)\n",
        "    #     print(\"Building vocab (word-id mapping)..\")\n",
        "    #     gc.collect() # force garbage collection\n",
        "    #     sent_gen = (sent for text in self._texts for sent in text)\n",
        "    #     if min_word_freq:\n",
        "    #         self.vocab = build_vocab_from_iterator(sent_gen, specials=[self.unkn_tok], min_word_freq=5)\n",
        "    #     else:\n",
        "    #         words = Counter()\n",
        "    #         for tokens in sent_gen:\n",
        "    #             words.update(tokens)\n",
        "    #         words = [word for word, freq in words.most_common(max_word_count)] # list sorted by frequency yikees\n",
        "    #         self.vocab = Vocab(VocabPybind(words, None))\n",
        "    #     self.vocab.insert_token(self.unkn_tok, 0)\n",
        "    #     self.vocab.set_default_index(self.vocab[self.unkn_tok]) # set index for out-of-vocabulary words\n",
        "    #     print(\"Mapping words to ids..\")\n",
        "    #     gc.collect() # force garbage collection\n",
        "    #     self._texts = self.id_map_reviews(self._texts)\n",
        "    #     gc.collect() # force garbage collection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WNOfjsmm6K53",
        "outputId": "7793e946-ca1e-4e0c-e363-640c184fca95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([1.744843 , 1.7353735, 1.7136729, 1.689487 , 1.6631922, 1.6536332,\n",
            "       1.6488355, 1.6264031, 1.5831056, 1.5831056, 1.5075598, 1.5013322,\n",
            "       1.4843978, 1.4728191, 1.4696563, 1.4696563, 1.4542516, 1.4179466,\n",
            "       1.4006785, 1.3984987], dtype=float32), array([551847, 736133, 799523, 889229, 527777, 913742, 912466, 799479,\n",
            "       915216, 914505,  33244, 620038, 747994, 443505, 248951, 403976,\n",
            "       914359, 237131,  26372, 912573]))\n",
            "[3. 4. 3. 4. 9.]\n"
          ]
        }
      ],
      "source": [
        "rb = RateBeerFasttextReviews(vec_agg='avg')\n",
        "# rb.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# rb.model = model # same as above\n",
        "# rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-avg-fasttext-vecs.pt')\n",
        "# rb.build(filepath='/drive/MyDrive/Colab Notebooks/1e100ibu/SNAP-Ratebeer.txt', max_reviews=1e6)\n",
        "rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-avg-fasttext-vecs.pt')\n",
        "print(rb.closest_indices('Worst beer i have ever seen')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(rb.knn_predict_rating('Tastes best from bottle. Not so heap as one could think. Nice hoppy smell. I had not supposed it will be sour though. Beautiful smooth head.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gm2AjJ8g6K53"
      },
      "outputs": [],
      "source": [
        "pipe = rb.pipe # reuse old pipe and model when prototyping using notebook\n",
        "model = rb.model # same as above"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bN74naT6K53",
        "outputId": "7c98a5ca-c0c1-46a1-f1b6-49a854f18404"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(array([22.735153, 22.64056 , 22.516415, 22.23186 , 22.160046, 22.048971,\n",
            "       21.934198, 21.886766, 21.850925, 21.694199, 21.594963, 21.365963,\n",
            "       21.356918, 21.258148, 21.112421, 21.022198, 21.009058, 20.928476,\n",
            "       20.841497, 20.830072], dtype=float32), array([361933, 304525, 918293, 258243, 871224, 441608, 425355,  16229,\n",
            "       514749, 680937, 656630, 532489, 234424, 215026, 981224, 231571,\n",
            "       395523, 623433, 431470, 188537]))\n",
            "[ 4.  7.  4.  7. 14.]\n"
          ]
        }
      ],
      "source": [
        "# pipe = rb.pipe\n",
        "rb = RateBeerFasttextReviews(vec_agg='maxpool')\n",
        "# rb.pipe = pipe # kinda cache by using old pipe and model when prototyping using notebook\n",
        "# rb.model = model # same as above\n",
        "# rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-maxpool-fasttext-vecs.pt')\n",
        "# rb.build(filepath='/drive/MyDrive/Colab Notebooks/1e100ibu/SNAP-Ratebeer.txt', max_reviews=1e6)\n",
        "rb.load(dest_path=MODEL_ROOT_DIR, filename='ratebeer-maxpool-fasttext-vecs.pt')\n",
        "print(rb.closest_indices('Worst beer i have ever seen')) # check: this input is 0-th review from the dataset, so hope for 0 be the most similar\n",
        "print(rb.knn_predict_rating('Tastes best from bottle. Not so heap as one could think. Nice hoppy smell. I had not supposed it will be sour though. Beautiful smooth head.'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfunH0-g6K53",
        "outputId": "e4fb26c7-1b79-4cbc-f480-72805abb75db"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(999968, 300)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "rb._texts.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl1fjmMI6K54",
        "outputId": "e869d344-82cc-4ebe-eb5c-eb9147ff91c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['word', 'word', 'word', 'word'], ['word', 'word', 'word', 'word']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "rb.pipe(['word. word word word', 'word. word word word'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DejU2vjo6K54",
        "outputId": "ef8888ba-cea7-4aaf-d1e5-d3e37a710ab7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([3.733626 , 3.6719368, 3.635041 , 3.5646927, 3.509334 , 3.5045424,\n",
              "        3.494309 , 3.4663272, 3.4423547, 3.4316068, 3.4291258, 3.4210002,\n",
              "        3.4116852, 3.4064589, 3.398675 , 3.3939714, 3.3930357, 3.3901331,\n",
              "        3.3887985, 3.3885772], dtype=float32),\n",
              " array([304525, 425355, 871224, 361933, 514749,  81678, 918293, 178517,\n",
              "        441608, 916052, 114259,  16229, 227491, 359045, 296080, 786202,\n",
              "        750604, 215026, 258243, 680937]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "rb.closest_indices('Fatalne piwo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH5fTMZn6K54",
        "outputId": "c37b7a64-c8f4-47df-adc0-3eeb535a584e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.,  7.,  3.,  7., 13.], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "rb.knn_predict_rating('Fatalne piwo.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "oN63fJkW6K54",
        "outputId": "0ea42f49-e4e6-4786-b9e4-f8ab785a7016"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-0f1349d85b66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for i in [400, 605, 540, 269, 323, 560, 499,  19, 857, 624, 528, 234,   0,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#                     697, 581, 898, 781, 601, 322,  21]:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_texts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name '_texts' is not defined"
          ]
        }
      ],
      "source": [
        "# for i in [ 7,  2,  4,  5,  9,  0,  1,  6,  3,  8, -1, -1, -1, -1, -1, -1, -1,\n",
        "#         -1, -1, -1]:\n",
        "# # for i in [400, 605, 540, 269, 323, 560, 499,  19, 857, 624, 528, 234,   0,\n",
        "# #                     697, 581, 898, 781, 601, 322,  21]:\n",
        "#     print(_texts[i], '\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4bM2pyPyG7Px"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "1e100ibu-embedding-stars.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}