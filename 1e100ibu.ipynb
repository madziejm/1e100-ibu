{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1e100ibu.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madziejm/1e100-ibu/blob/master/1e100ibu.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dependencies siorbing"
      ],
      "metadata": {
        "id": "CT48xPyXJHy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchtext\n",
        "import io\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data import get_tokenizer\n",
        "\n",
        "import torch\n",
        "\n",
        "dev = 'cuda' if torch.cuda.is_available else 'cpu'"
      ],
      "metadata": {
        "id": "Sl9RJDTxJOTY"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install icecream\n",
        "from icecream import ic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yet9JpBt8kcx",
        "outputId": "1aad5eb6-f4f0-46ba-edcd-ea917d3fd408"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting icecream\n",
            "  Downloading icecream-2.1.1-py2.py3-none-any.whl (8.1 kB)\n",
            "Collecting executing>=0.3.1\n",
            "  Downloading executing-0.8.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting colorama>=0.3.9\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Collecting asttokens>=2.0.1\n",
            "  Downloading asttokens-2.0.5-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: pygments>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from icecream) (2.6.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from asttokens>=2.0.1->icecream) (1.15.0)\n",
            "Installing collected packages: executing, colorama, asttokens, icecream\n",
            "Successfully installed asttokens-2.0.5 colorama-0.4.4 executing-0.8.2 icecream-2.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Dataset siorbing"
      ],
      "metadata": {
        "id": "JcpSzAJmFV56"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ8cumFHEEQd",
        "outputId": "9ec912d7-f0a4-4a8a-e821-e28baa2e126b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12tEEYQcHZtg5aWyfIiWWVIDAJNT-5d_T\n",
            "To: /content/SNAP-Ratebeer.txt\n",
            "100% 1.74G/1.74G [00:19<00:00, 91.2MB/s]\n",
            "Dataset head (trailing newline makes entry end): \n",
            "beer/name: John Harvards Simcoe IPA\n",
            "beer/beerId: 63836\n",
            "beer/brewerId: 8481\n",
            "beer/ABV: 5.4\n",
            "beer/style: India Pale Ale &#40;IPA&#41;\n",
            "review/appearance: 4/5\n",
            "review/aroma: 6/10\n",
            "review/palate: 3/5\n",
            "review/taste: 6/10\n",
            "review/overall: 13/20\n",
            "review/time: 1157587200\n",
            "review/profileName: hopdog\n",
            "review/text: On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.\n",
            "\n",
            "beer/name: John Harvards Simcoe IPA\n",
            "beer/beerId: 63836\n"
          ]
        }
      ],
      "source": [
        "RATEBEER_FILE = '/content/SNAP-Ratebeer.txt'\n",
        "! export RATEBEER_FILE='/content/SNAP-Ratebeer.txt'\n",
        "! [ -e $RATEBEER_FILE ] || gdown --id '12tEEYQcHZtg5aWyfIiWWVIDAJNT-5d_T' # https://drive.google.com/file/d/12tEEYQcHZtg5aWyfIiWWVIDAJNT-5d_T/view?usp=sharing\n",
        "! echo \"Dataset head (trailing newline makes entry end): \"\n",
        "! head -n 16 $RATEBEER_FILE\n",
        "! iconv -f ISO-8859-1 -t UTF-8 $RATEBEER_FILE -o {RATEBEER_FILE}.new && mv {RATEBEER_FILE}.new $RATEBEER_FILE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Vocab representation"
      ],
      "metadata": {
        "id": "hAp1vxv0JBmy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "UNKNOWN_TOKEN = \"<unk>\"\n",
        "\n",
        "tokenizer = get_tokenizer('basic_english')\n",
        "def create_vocab(dataset_path):\n",
        "  def yield_tokens():\n",
        "    with io.open(dataset_path, encoding='utf-8') as f:\n",
        "      for line in f:\n",
        "        review_text_prefix = 'review/text: '\n",
        "        if line.startswith(review_text_prefix):\n",
        "          line = line[len(review_text_prefix):] # drop prefix\n",
        "          yield tokenizer(line) # TODO remove punctuation\n",
        "          # line = line.strip().lower().split() \n",
        "  vocab = build_vocab_from_iterator(yield_tokens(), specials=[UNKNOWN_TOKEN])\n",
        "  vocab.set_default_index(vocab[UNKNOWN_TOKEN])\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "2W2kAaEJI_iI"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = create_vocab(RATEBEER_FILE)"
      ],
      "metadata": {
        "id": "LQJqC6WDcYyQ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Test `vocab`"
      ],
      "metadata": {
        "id": "JJkKGVlznDad"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "review = 'On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.'\n",
        "ided_review = vocab.lookup_indices(tokenizer(review))\n",
        "print(f'id-ed review: {ided_review}')\n",
        "word_count = len(vocab.get_itos())\n",
        "print(f'word count: {word_count}')\n",
        "print(f'most common words: {vocab.get_itos()[:30]}')\n",
        "# try whether we can get an id for unknown token (which will be probably 0 as it's index of unknown token)\n",
        "print(f'{vocab.lookup_indices([\"lubie\", \"hamburgefonsz\"])}')\n",
        "# TODO remove keep only n most common words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CghoFLGMnHbF",
        "outputId": "91464a39-cd9c-4a81-918a-59e57c76ab4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "id-ed review: [29, 123, 34, 5, 10719, 2, 2038, 1225, 1, 125, 3, 135, 4, 160, 75, 52, 138, 3, 183, 51, 45, 6, 3, 81, 398, 141, 32, 9, 1, 187, 139, 684, 4, 103, 315, 490, 1, 177, 7, 684, 2, 19, 39, 4, 3, 18, 19, 179, 26, 1, 15, 87, 145, 23, 923, 5, 47920, 1693, 79, 15, 488, 13, 65, 11, 107, 3, 18, 19, 70, 6, 3, 42, 95, 11, 16, 1, 19, 92, 392, 29, 5, 149, 1]\n",
            "word count: 641357\n",
            "most common words: ['<unk>', '.', ',', 'a', 'and', 'the', 'with', 'of', 'is', 'head', 'aroma', 'to', 'in', 'this', 'but', 'i', 'it', 'sweet', 'very', 'light', 'beer', 'some', 'flavor', 'not', 'malt', 'bottle', 'finish', 'nice', 'that', 'on']\n",
            "[0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test gradients"
      ],
      "metadata": {
        "id": "fxqV0tl4rnO3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "values = torch.tensor([1.0, 2.0, 3.0], requires_grad=True)\n",
        "l2_loss = values.square().sum()\n",
        "# l2_loss.zero_grad()\n",
        "l2_loss.backward()\n",
        "\n",
        "print(values.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PG0oYrrgn9S7",
        "outputId": "b6c4b687-19f4-469d-b40e-823f78ef4481"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([2., 4., 6.])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yyyy"
      ],
      "metadata": {
        "id": "7Wm7d-2lwgSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "aspects = ['appearance', 'aroma', 'palate', 'taste', 'overall']\n",
        "aspect_count = len(aspects)"
      ],
      "metadata": {
        "id": "eUoc6febB8vQ"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# theta = torch.empty(word_count, aspect_count, requires_grad=True)\n",
        "theta = torch.rand((word_count, aspect_count), requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    theta *= 0.9\n",
        "#   torch.nn.init.kaiming_uniform_(theta)\n",
        "  # enforce 1 initialization on aspect name (page 4)\n",
        "    aspect_ids = vocab.lookup_indices(aspects)\n",
        "    theta[aspect_ids, :] = 1\n",
        "\n",
        "# phi = torch.rand((word_count, , aspect_count), requires_grad=True)\n",
        "\n",
        "aspect_rating_count = [6, 11, 6, 11, 21]\n",
        "phis = [torch.rand((word_count, aspect_rating_count[i]), requires_grad=True) for i in range(aspect_count)]\n",
        "\n",
        "with torch.no_grad():\n",
        "    # normalize that sum across all words is 1 for a given aspect (eq. 7)\n",
        "    phis = [phi / phi.sum(dim=0) for phi in phis]\n",
        "for phi in phis:\n",
        "    phi.requires_grad = True\n"
      ],
      "metadata": {
        "id": "VGjeZUFLsZ5e"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def review_text2ids(review_text: str):\n",
        "  return vocab.lookup_indices(tokenizer(review_text))\n",
        "\n",
        "# def review_text2weights(review_text: str):\n",
        "#   ids = review_text2ids(review_text)\n",
        "#   thetas = theta[ids]\n",
        "#   phis   = phi[ids]\n",
        "#   return thetas, phis\n",
        "\n",
        "# def review_likelihood(review_text: str):\n",
        "#   theta_weight, phi_weight = 1.0, 1.0\n",
        "#   thetas, phis = review_text2weights(review_text)\n",
        "#   return torch.mean(\n",
        "#       theta_weight * thetas +\n",
        "#       phi_weight * phis\n",
        "#   )"
      ],
      "metadata": {
        "id": "qbpx6lSOwfkg"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_likelihood('Ich trinke Bier gern')"
      ],
      "metadata": {
        "id": "-7FWEmRcxGuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_likelihood('Amazing hops and taste')"
      ],
      "metadata": {
        "id": "JEGHzhrmMea4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "review_likelihood('appearance aroma palate taste overall')"
      ],
      "metadata": {
        "id": "HE-sIjQrLRvA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(theta)"
      ],
      "metadata": {
        "id": "MkkI6bVbLk0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab.lookup_indices(aspects)"
      ],
      "metadata": {
        "id": "NU5p9ZeMLnz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ClLM3hVCL96o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Implementation of $(1)$"
      ],
      "metadata": {
        "id": "yOc_2b-E4o0c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ratebeer(review):\n",
        "    \"\"\"\n",
        "    get review like this\n",
        "    \n",
        "    beer/name: John Harvards Simcoe IPA\n",
        "    beer/beerId: 63836\n",
        "    beer/brewerId: 8481\n",
        "    beer/ABV: 5.4\n",
        "    beer/style: India Pale Ale &#40;IPA&#41;\n",
        "    review/appearance: 4/5\n",
        "    review/aroma: 6/10\n",
        "    review/palate: 3/5\n",
        "    review/taste: 6/10\n",
        "    review/overall: 13/20\n",
        "    review/time: 1157587200\n",
        "    review/profileName: hopdog\n",
        "    review/text: On tap at the Springfield, PA location. Poured a deep and cloudy orange (almost a copper) color with a small sized off white head. Aromas or oranges and all around citric. Tastes of oranges, light caramel and a very light grapefruit finish. I too would not believe the 80+ IBUs - I found this one to have a very light bitterness with a medium sweetness to it. Light lacing left on the glass.\n",
        "    \n",
        "    return review text as list of sentences and aspect ratings\n",
        "    \"\"\""
      ],
      "metadata": {
        "id": "1rYfSug_5Vlf"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "def yield_ided_review(dataset_path=RATEBEER_FILE, max_lines=1000000000):\n",
        "    with io.open(dataset_path, encoding='utf-8') as f:\n",
        "        counter = 0\n",
        "        review_lines = []\n",
        "        for line, _ in zip(f, range(max_lines)):\n",
        "            if counter < 13:\n",
        "                review_lines.append(line)\n",
        "                counter += 1\n",
        "            else:\n",
        "                review_aspects_scores = review_lines[5:10]\n",
        "                review_aspects_scores = list(map(lambda s: int(s.split(': ')[1].split('/')[0]), review_aspects_scores))\n",
        "                \n",
        "                # wywalamy review/text\n",
        "                review_sentences = review_lines[12].lower()[len(\"review/text: \"):]\n",
        "                if line.startswith(\"UPDATED:\"):\n",
        "                    review_sentences = review_sentences[len(\"UPDATED: APR 29, 2008\"):] # drop prefix\n",
        "                \n",
        "                review_sentences = review_sentences.split('.')\n",
        "                review_sentences = list(filter(lambda l: len(l) != 0, (map(review_text2ids, review_sentences))))\n",
        "                result = (review_sentences, review_aspects_scores)\n",
        "                # raise BaseException\n",
        "                yield (review_sentences, review_aspects_scores) # TODO remove punctuation\n",
        "                # line = line.strip().split()\n",
        "                counter = 0\n",
        "                review_lines = []\n",
        "\n"
      ],
      "metadata": {
        "id": "3FhhxmWw4rGB"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ided_reviews = yield_ided_reviews(max_lines=int(2e6))"
      ],
      "metadata": {
        "id": "daY1ZHl4-glT"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sentence_aspects_likelihood_theta(sen_ids):\n",
        "    theta_theta = theta[sen_ids]\n",
        "    theta_score = theta_theta\n",
        "    return theta_score\n",
        "\n",
        "def sentence_aspects_likelihood_phi(sen_ids):\n",
        "    phi_scores = [phis[aspect_idx][sen_ids, :] for aspect_idx in range(aspect_count)]\n",
        "    return phi_scores\n",
        "\n",
        "# def sentence_aspects_likelihood(sen_ids):\n",
        "#     theta_score = sentence_aspects_likelihood_theta(sen_ids)\n",
        "#     phi_scores = sentence_aspects_likelihood_phi(sen_ids)\n",
        "#     ic(theta_score, phi_scores)\n",
        "\n",
        "    # score = torch.exp( + sentence_aspects_likelihood_phi(sen_ids, ratings))\n",
        "    # return score / score.sum()\n"
      ],
      "metadata": {
        "id": "-BbREMkrBEph"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (review_sentences, review_aspects_scores) in yield_ided_review(max_lines=int(2e6)):\n",
        "    for sen_ids in review_sentences:\n",
        "        theta_scores = sentence_aspects_likelihood_theta(sen_ids)\n",
        "        aspect_pred = int(torch.argmax(torch.nn.functional.softmax(theta_scores.sum(0))).item())\n",
        "\n",
        "        pred_aspect_rating = review_aspects_scores[aspect_pred]\n",
        "        phi_score = sentence_aspects_likelihood_phi(sen_ids)[aspect_pred][:, pred_aspect_rating]\n",
        "        \n",
        "        asd = (theta_scores[:, aspect_pred] + phi_score).sum()\n",
        "        ic(asd)\n",
        "\n",
        "        ic(torch.square(theta).sum())\n",
        "        \n",
        "        # ic(torch.hstack(list(torch.square(phi).sum() for phi in phis)).sum())\n",
        "        \n",
        "        loss = -asd\n",
        "        loss.backward()\n",
        "        ic(theta.grad)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            theta -= 0.01 * theta.grad\n",
        "            phis = [phi - 0.01 * phi.grad if phi.grad != None else phi for phi in phis ]\n",
        "        raise BaseException\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "UR2BLDFGCNdi",
        "outputId": "3ab9ecb1-c984-46e2-c326-5e5b4b79f8d1"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  after removing the cwd from sys.path.\n",
            "ic| asd: tensor(5.7028, grad_fn=<SumBackward0>)\n",
            "ic| torch.square(theta).sum(): tensor(865644., grad_fn=<SumBackward0>)\n",
            "ic| theta.grad: tensor([[  0.,   0.,   0.,   0.,   0.],\n",
            "                        [  0.,   0.,   0.,   0.,   0.],\n",
            "                        [  0., -24.,   0.,   0.,   0.],\n",
            "                        ...,\n",
            "                        [  0.,   0.,   0.,   0.,   0.],\n",
            "                        [  0.,   0.,   0.,   0.,   0.],\n",
            "                        [  0.,   0.,   0.,   0.,   0.]])\n",
            "ic| phis[0].requires_grad: True\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BaseException",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBaseException\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-107-6253694c3e77>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0mtheta\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtheta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mphis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mphi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.01\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mphi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mphi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mphis\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mBaseException\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBaseException\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def review_aspect_likelihoods(review_sentences: str):\n",
        "#   theta_weight, phi_weight = 1.0, 1.0\n",
        "#   thetas, phis = review_text2weights(review_text)\n",
        "#     for s in review_sentences:\n",
        "\n",
        "# #   return map(\n",
        "# #       lambda s:,\n",
        "# #       review_sentences\n",
        "# #   )\n",
        "#   return torch.mean(\n",
        "#       theta_weight * thetas +\n",
        "#       phi_weight * phis\n",
        "#   )"
      ],
      "metadata": {
        "id": "8e_lSSOF_XdK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}